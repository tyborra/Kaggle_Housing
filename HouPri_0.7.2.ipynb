{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "import lightgbm as lgb\n",
    "import tensorflow as tf\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Feathers and Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1453, 312)    (1459, 312)    (1453,)    (1459,)\n"
     ]
    }
   ],
   "source": [
    "#current #1\n",
    "import feather\n",
    "#Feathers\n",
    "X_train = pd.read_feather(r'C:\\Users\\user\\Desktop\\Kaggle\\HousePrices\\Feathers\\X_train_FE_D_13.feather')\n",
    "test = pd.read_feather(r'C:\\Users\\user\\Desktop\\Kaggle\\HousePrices\\Feathers\\test_FE_D_13.feather')\n",
    "\n",
    "#csv\n",
    "y_temp = pd.read_csv(r'C:\\Users\\user\\Desktop\\Kaggle\\HousePrices\\Feathers\\y_train_FE_D_13.csv', low_memory = False, header = None, names = 'y')\n",
    "y_train = y_temp['y']\n",
    "\n",
    "test_ID_temp = pd.read_csv(r'C:\\Users\\user\\Desktop\\Kaggle\\HousePrices\\Feathers\\test_ID.csv', low_memory = False, header = None, names = 'i')\n",
    "test_ID = test_ID_temp['i']\n",
    "\n",
    "print(X_train.shape,\"  \",test.shape,\"  \",y_train.shape, \"  \", test_ID.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New best, submission_42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import feather\n",
    "#Feathers\n",
    "X_train = pd.read_feather(r'C:\\Users\\user\\Desktop\\Kaggle\\HousePrices\\Feathers\\X_train_FE_D_11.feather')\n",
    "test = pd.read_feather(r'C:\\Users\\user\\Desktop\\Kaggle\\HousePrices\\Feathers\\test_FE_D_11.feather')\n",
    "\n",
    "#csv\n",
    "y_temp = pd.read_csv(r'C:\\Users\\user\\Desktop\\Kaggle\\HousePrices\\Feathers\\y_train_FE_D_11.csv', low_memory = False, header = None, names = 'y')\n",
    "y_train = y_temp['y']\n",
    "\n",
    "test_ID_temp = pd.read_csv(r'C:\\Users\\user\\Desktop\\Kaggle\\HousePrices\\Feathers\\test_ID.csv', low_memory = False, header = None, names = 'i')\n",
    "test_ID = test_ID_temp['i']\n",
    "\n",
    "print(X_train.shape,\"  \",test.shape,\"  \",y_train.shape, \"  \", test_ID.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLXTEND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlextnd\n",
    "\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "\n",
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=4321))\n",
    "\n",
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05, max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, loss='huber', random_state =5)\n",
    "\n",
    "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,learning_rate=0.05, n_estimators=720, max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319, feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11, n_jobs = 1)\n",
    "\n",
    "model_xgb =  xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, learning_rate=0.05, max_depth=3, min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571, subsample=0.5213, silent=1,random_state =7, nthread = -1, n_jobs = 1)\n",
    "\n",
    "model_xgb_2 = xgb.XGBRegressor(learning_rate =0.01, n_estimators=3460, max_depth=3,min_child_weight=0 ,\n",
    "                                     gamma=0, subsample=0.7,colsample_bytree=0.7,objective= 'reg:linear',nthread=4,\n",
    "                                     scale_pos_weight=1,seed=27, reg_alpha=0.00006)\n",
    "\n",
    "model_xgb_3 = make_pipeline(RobustScaler(), xgb.XGBRegressor( colsample_bytree=0.2, gamma=0.0, learning_rate=0.01, max_depth=4,\n",
    "                     min_child_weight=1.5, n_estimators=7200, reg_alpha=0.9, reg_lambda=0.6, subsample=0.2, seed=4321,\n",
    "                     silent=1))\n",
    "\n",
    "RF_model = RandomForestRegressor(n_estimators=500, min_samples_leaf=1, max_features = 0.5, n_jobs = 1, \n",
    "                                 oob_score = True, random_state = 4321)\n",
    "\n",
    "#stack\n",
    "stack_gen = StackingCVRegressor(regressors = (lasso, GBoost, model_xgb_2, model_lgb), meta_regressor = lasso,\n",
    "                                            use_features_in_secondary=True) #use_features_in_secondary=True uses original dat and results\n",
    "\n",
    "#prepare dataframes\n",
    "stack_X = np.array(X_train)\n",
    "stack_y = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlxt_model = stack_gen.fit(stack_X, stack_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modified for stack_gen\n",
    "n_folds = 5\n",
    "\n",
    "def rmsle_cv_stack(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(X_train.values)\n",
    "    rmse= np.sqrt(-cross_val_score(model, stack_X, stack_y, scoring=\"neg_mean_squared_error\", cv = kf, verbose = 2))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 3.5min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total= 3.4min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 3.5min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 3.5min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 3.4min\n",
      "\n",
      "Stack score: 0.1019 (0.0057)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 17.3min finished\n"
     ]
    }
   ],
   "source": [
    "#stack_gen CV\n",
    "score = rmsle_cv_stack(mlxt_model)\n",
    "print(\"\\nStack score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.regressor import StackingRegressor\n",
    "\n",
    "stack_2_gen = StackingRegressor(regressors = (lasso, GBoost, model_xgb_2, model_lgb), meta_regressor = lasso)\n",
    "\n",
    "#prepare dataframes\n",
    "stack_X = np.array(X_train)\n",
    "stack_y = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlxt_2_model = stack_2_gen.fit(stack_X, stack_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stack_2_gen CV\n",
    "score = rmsle_cv_stack(mlxt_2_model)\n",
    "print(\"\\nStack_2 score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sound******************************\n",
    "import winsound\n",
    "duration = 500  # millisecond\n",
    "freq = 500\n",
    "freq_2 = 450  # Hz\n",
    "winsound.Beep(freq, duration)\n",
    "winsound.Beep(freq_2, duration)\n",
    "winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance MLExtnd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### view features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FI_mlxt = pd.DataFrame({\"Feature Importance\":mlxt_2_model.coef_}, index = X_train.columns)\n",
    "FI_mlxt.sort_values(\"Feature Importance\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FI_mlxt[FI_mlxt[\"Feature Importance\"]!=0].sort_values(\"Feature Importance\").plot(kind=\"barh\",figsize=(15,25))\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reduce features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlxt_feat_importance(m, df):\n",
    "    return pd.DataFrame({'cols':df.columns, 'imp':m.coef_}).sort_values('imp', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = mlxt_feat_importance(mlxt_2_model, X_train)\n",
    "fi[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_keep = fi[fi.imp>0.0000001].cols\n",
    "len(to_keep)\n",
    "to_keep = to_keep.append(fi[fi.imp<-0.0000001].cols)\n",
    "len(to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equal_zero = fi[fi.imp == 0].cols\n",
    "len(equal_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[to_keep].copy()\n",
    "test = test[to_keep].copy()\n",
    "X_train.shape\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(X_train.values)\n",
    "    rmse= np.sqrt(-cross_val_score(model, X_train.values, y_train, scoring=\"neg_mean_squared_error\", cv = kf, verbose = 2))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=4321))\n",
    "#lasso = Lasso(alpha =0.0005, random_state=4321)\n",
    "\n",
    "%time lasso.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LASSO CV\n",
    "score = rmsle_cv(lasso)\n",
    "print(\"\\nLASSO score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked Models mlens Superlearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlens\n",
    "from mlens.ensemble import SuperLearner\n",
    "from mlens.metrics.metrics import rmse\n",
    "\n",
    "ensemble = SuperLearner(scorer=rmse, random_state=4321, verbose=1, backend = 'multiprocessing', folds=10, n_jobs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.add([ GBoost, model_lgb, lasso], backend = 'multiprocessing', folds=5, n_jobs = 1)\n",
    "ensemble.add_meta(lasso, backend = 'multiprocessing', folds=10)\n",
    "ensemble_model = ensemble.fit(X_train, y_train, backend = 'multiprocessing', folds=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score = rmsle_cv(ensemble)\n",
    "\n",
    "print(\"\\n Ensemble score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalized Weight *Convert to function later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_score = pd.DataFrame()\n",
    "\n",
    "kaggle_score['Score'] = [1-.14039, 1-.12425, 1-.12494, 1-.12218, 1-.1253, 1-.11862]\n",
    "#print(kaggle_score)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0.1, .99))\n",
    "scaler.fit(kaggle_score)\n",
    "#scaler.transform(kaggle_score)\n",
    "\n",
    "kaggle_min_max = scaler.fit_transform(kaggle_score)\n",
    "#print(kaggle_min_max)\n",
    "kaggle_score['min_max']= kaggle_min_max\n",
    "kaggle_score['Model'] = ['RF','Lasso','GBoost','LGBM', 'XGB', 'meta']\n",
    "kaggle_score['weight']= (kaggle_score['min_max']/(kaggle_score['min_max'].sum(axis = 0)))*100\n",
    "print(kaggle_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "light_gbm_pred = np.expm1(model_lgb.predict(test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_pred = np.expm1(model_xgb.predict(test))  #remove .values for xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weighted_pred = (light_gbm_pred *0.40 +Lasso_pred * 0.25 + GBoost_pred * 0.25 + RF_pred * 0.10) *****Best***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weighted_pred_2 = (light_gbm_pred *0.27 +Lasso_pred * 0.24 + GBoost_pred * 0.23+ XGB_pred * 0.23 + RF_pred * 0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_pred_meta = (ensemble_pred * 0.26 + light_gbm_pred *0.21 +Lasso_pred * 0.18 + GBoost_pred * 0.18+ XGB_pred * 0.17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_pred = np.expm1(averaged_models.predict(test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_pred = np.expm1(ensemble_model.predict(test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlxt_pred = np.expm1(mlxt_model.predict(test.values))   #****MLXT*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_avg_pred = (mlxt_pred * 0.50 + ensemble_pred *0.50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub_1 = pd.DataFrame()\n",
    "sub_1['Id'] = test_ID\n",
    "sub_1['SalePrice'] = mlxt_pred\n",
    "sub_1.to_csv('submission_44.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
